{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "A6kPXU52_07x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web scraping is the process of extracting data from websites using software. It can be done with a bot or web crawler that simulates human web surfing or with HTML requests that inform the website code of what data to copy. Web scraping is used for various purposes such as collecting information for analysis, comparison, or indexing. Here are three areas where web scraping is used to get data:\n",
        "\n",
        "* Crawling and indexing websites for search engines.\n",
        "* Collecting data for market research or competitor analysis.\n",
        "* Populating news feeds"
      ],
      "metadata": {
        "id": "ek1xfZBA_4XL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "TjjBcZobACrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular APIâ€™s or even creating your code for web scraping from scratch. Here are some of the most common techniques used for Web Scraping:\n",
        "\n",
        "* Human copy-and-paste\n",
        "* Text pattern matching\n",
        "* HTTP programming\n",
        "* HTML parsing\n",
        "* DOM parsing\n",
        "* Vertical aggregation\n",
        "* Semantic annotation recognizing"
      ],
      "metadata": {
        "id": "W3EDNN00AEeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "kDQmYFkLBKvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful Soup is a Python package used for parsing HTML and XML documents. It creates a parse tree for parsed pages which can be used for web scraping, and pulls data from HTML and XML files. It provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. Beautiful Soup is used for web-scraping and is a great tool for extracting information from large unstructured data. As a Python library used for pulling data from HTML, XML, and other markup language files, Beautiful Soup can extract articles and content and turn it into a Python list or dictionary."
      ],
      "metadata": {
        "id": "6z3q1oJpBMWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4"
      ],
      "metadata": {
        "id": "WtVVn_v3BV9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flask is a Python web framework that is used to build web applications. It is a micro-framework that is used to build small web applications. Flask is used in Web Scraping projects because it provides a simple way to create web applications that can be used to display the scraped data. Flask can be used to create a simple web application that can display the scraped data in a table or graph."
      ],
      "metadata": {
        "id": "c2NB0fqcBYgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5"
      ],
      "metadata": {
        "id": "D7wTxzplBo57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sevices used in this project are :\n",
        "\n",
        "* Beanstalk : AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web applications and services. It provides an environment for hosting your web applications that automatically handles the deployment.\n",
        "\n",
        "* CodePipeline : AWS CodePipeline is a continuous integration and continuous delivery (CI/CD) service used to build, test, and deploy code.CodePipeline integrates with other AWS services like Elastic Beanstalk, CodeCommit, CodeBuild, CodeDeploy allowing the user to build a complete CI/CD pipeline."
      ],
      "metadata": {
        "id": "29rO4jjkBoyk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaozffwP_37C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}